---
title: "Dossier - Modelos Bayesianos"
author: "Iker Cuadros Ruiz y Roger Pastor Juan"
date: '`r Sys.Date()`'
output:
  html_document: default
  pdf_document:
        latex_engine: xelatex
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE}
if (!require(extraDistr)) install.packages("extraDistr")
library(extraDistr)

if (!require(modeest)) install.packages("modeest")
library(modeest) # Para calcular la moda

if (!require(LaplacesDemon)) install.packages("LaplacesDemon")
library(LaplacesDemon)

if (!require(MASS)) install.packages("MASS")
library(MASS)

if (!require(metRology)) install.packages("metRology")
library(metRology)

if (!require(jagsUI)) install.packages("jagsUI")
library(jagsUI)

if (!require(faraway)) install.packages("faraway")
library(faraway)

if (!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)

if (!require(tidyr)) install.packages("tidyr")
library(tidyr)
```

# PRÁCTICA 1: ELEMENTOS ESTADÍSTICA BAYESIANA

## Actividad 1: Conciertos y asientos

¡Este fin de semana me voy de concierto a un festival! Al llegar a la
entrada con mis dos amigas nos encontramos con la siguiente situación:
solo hay $100$ sillas y se han vendido $120$ entradas, por lo que no hay
asientos para todas las personas. Sin entrar a valorar como se consigue
el asiento, es decir, asumiendo que se consigue de forma aleatoria,
considera la variable aleatoria que indica cuantas de mis amigas
(incluida yo) conseguimos asiento.

**Ayuda:** utiliza probabilidades condicionadas y ten cuidado con el
reemplazamiento.

Nuestra variable de interés será X que se representa como cuantos amigos
consiguen un asiento.

-   Calcula y representa su función de probabilidad.

Hay 4 posibles casos de X, $X = \{0,1,2,3\}$

Para $X=0$:

$$P(X=0)=P(S1^{c}) \cap P(S2^{c}) \cap P(S3^{c})$$

$$P(X=0)=\frac{20}{120} \cdot \frac{19}{119} \cdot \frac{18}{118}= \frac{57}{14042}=0.004$$
$$P(X=0)=0.004$$

Para $X = 1$:

$$
P(X=1)=P(S1 \cap S2^{c} \cap S3^{c}) + P(S1^{c} \cap S2 \cap S3^{c}) + P(S1^{c} \cap S2^{c} \cap S3)
$$

$$
P(X=1) = \\
    P(S1 | S2^{c} \cap S3^{c}) \cdot P(S2^{c} | S3^{c}) \cdot P(S3^{c}) + \\
    P(S1^{c} | S2 \cap S3^{c}) \cdot P(S2 | S3^{c}) \cdot P(S3^{c}) +\\
    P(S1^{c} | S2^{c} \cap S3) \cdot P(S2^{c} | S3) \cdot P(S3)
$$

$$
P(X=1) = 3 \cdot \left( \frac{100 \cdot 20 \cdot 19}{120 \cdot 119 \cdot 118} \right)
$$

$$
P(X=1) = 0.068
$$

Para $X = 2$:

$$
P(X=2)=P(S1 \cap S2 \cap S3^{c}) + P(S1 \cap S2^{c} \cap S3) + P(S1^{c} \cap S2 \cap S3)
$$

$$
P(X=2) = \\
    P(S1 | S2 \cap S3^{c}) \cdot P(S2 | S3^{c}) \cdot P(S3^{c}) + \\
    P(S1 | S2^{c} \cap S3) \cdot P(S2^{c} | S3) \cdot P(S3) +\\
    P(S1^{c} | S2 \cap S3) \cdot P(S2 | S3) \cdot P(S3)
$$

$$
P(X=1) = 3 \cdot \left( \frac{99 \cdot 100 \cdot 20}{118 \cdot 119 \cdot 120} \right)
$$

$$
P(X=2) = 0.3525
$$

Para $X=3$:

$$P(X=0)=P(S1) \cap P(S2) \cap P(S3)$$

$$P(X=0)=\frac{100}{120} \cdot \frac{99}{119} \cdot \frac{98}{118}= \frac{1155}{2006}=0.576$$
$$P(X=0)=0.576$$

-   Calcula y representa su función de distribución.

$$
F_X(x) = \left\{
\begin{array}{ll}
0 & \text{para} \, -\infty \leq x \leq 0 \\
0.004 & \text{para} \, 0 \leq x < 1 \\
0.072 & \text{para} \, 1 \leq x < 2 \\
0.4245 & \text{para} \, 2 \leq x \leq 3 \\
1 & \text{para} \, 3 \leq x \leq \infty \\
\end{array}
\right.
$$

```{r}
# Definir las secciones de x y F(x)
x <- c(-Inf, 0, 1, 2, 3, Inf)
F_x <- c(0, 0, 0.004, 0.072, 0.4245, 1)
x_plot <- c(-10, 0, 1, 2, 3, 10)
F_plot <- c(0, 0, 0.004, 0.072, 0.4245, 1)

# Graficar
plot(x_plot, F_plot, type = "s", lwd = 2, col = "blue", 
     xlab = "x", ylab = "F_X(x)", 
     main = "Función de Distribución Acumulativa (CDF)")
grid()
points(x_plot, F_plot, pch = 19, col = "red")
```

-   Calcula la probabilidad de que al menos una de nosotras haya
    conseguido (no importa cual) asiento utilizando la función de
    probabilidad.

$$
P(X \geq 1) = 1 - P(X < 1) = 1 - P(X=0)
$$

$$
P(X \geq 1) = 1 - 0.004 = 0.996
$$

-   Calcula la probabilidad de que al menos una de nosotras haya
    conseguido (no importa cual) asiento utilizando la función de
    distribución.

$$
P(X \geq 1) = F_{X}(3) - F_{X}(0) = 1 - 0.004 = 0.996
$$

-   La probabilidad de que una de nosotras se tome una bebida depende de
    si se sienta ($0.3$) o no ($0.6$). Sabiendo que he tomado algo,
    calcula la probabilidad de que me haya sentado.

$$
P(S|B) = \frac{P(B|S) \cdot P(S)}{P(B)} =  \frac{P(B|S) \cdot P(S)}{P(B|S) \cdot P(B) + P(B|S^{c}) \cdot P(S^{c})}
$$

$$
P(S|B) = \frac{0.3 \cdot \left( \frac{100}{120} \right)}{0.3 \cdot \left( \frac{100}{120} \right) + 0.6 \cdot \left( 1- \frac{100}{120} \right)}
$$

$$
P(S|B) = \frac{5}{7} \approx 0.7143
$$

-   A última hora se han apuntado dos amigos tardones. Sabiendo que
    nosotras nos hemos sentado las tres y que ellos beben siempre,
    calcula la probabilidad de que nos hayamos tomado algo todos.

$$
P(B|S) \cdot P(B|S) \cdot P(B|S) \cdot 1 \cdot 1 = 0.3 \cdot 0.3 \cdot 0.3 \cdot 1 \cdot 1 = 0.027
$$

## Actividad 2: Viajes y COVID

Mañana te vas de viaje a un país que te pide una prueba de antígenos
negativa para poder entrar. Aunque tu vacuna te da tranquilidad, ¿crees
que las personas que viven en ese país pueden estar tranquilas con tu
viaje allí? Dicho de otra manera, ¿cómo de posible es que tengas COVID
aunque hayas dado negativo en la prueba de antígenos? El siguiente guión
te ayudará:

-   Asume una incidencia de COVID de $100$ casos por cada $100.000$
    habitantes.
-   Según se refleja en el prospecto del test empleado, su sensibilidad
    (probabilidad de dar positivo si se está enfermo) es del $72 \%$ y
    su especificidad (probabilidad de dar negativo si no se está
    enfermo) es del $99 \%$.

$$
P(C) = 0.001 \ ; \ P(C^{c}) = 0.999 \\
P(+ | C) = 0.72 \ ; \ P(- | C) = 0.28 \\
P(+ | C^{c}) = 0.01 \ ; \ P(- | C^{c}) = 0.99 \\
$$

-   Calcula la probabilidad de tener COVID condicionado a que has dado
    negativo.

$$
P(C|-) = \frac{P(-|C) \cdot P(C)}{P(-)} =  \frac{P(-|C) \cdot P(C)}{P(-|C) \cdot P(C) + P(-|C^{c}) \cdot P(C^{c})}
$$

$$
P(C|-) = \frac{0.28 \cdot 0.001}{0.28 \cdot 0.001 + 0.99 \cdot 0.999} = 0.00028
$$

-   Observa cómo se actualiza la probabilidad de tener COVID tras
    conocer que has dado negativo. Valora el cambio.

Vemos que ahora la probabilidad de tener COVID es realmente baja
comparada con la inicial

Visto el resultado anterior te planteas si esta probabilidad de tener
COVID tras saber que has dado negativo es la misma en todas las
Comunidades, independientemente de su incidencia.

-   Valora si la probabilidad condicionada anterior variaría para otra
    persona de otra Comunidad en la que la incidencia fuera de $500$
    casos por cada $100.000$ habitantes.

$$
P(C) = 0.005 \ ; \ P(C^{c}) = 0.995 \\
$$

$$
P(C|-) = \frac{P(-|C) \cdot P(C)}{P(-)} =  \frac{P(-|C) \cdot P(C)}{P(-|C) \cdot P(C) + P(-|C^{c}) \cdot P(C^{c})}
$$

$$
P(C|-) = \frac{0.28 \cdot 0.005}{0.28 \cdot 0.005 + 0.99 \cdot 0.995} = 0.00014
$$

-   A la vista del resultado anterior ¿crees que es relevante que las
    pruebas de antígenos se recomienden solo a las personas con síntomas
    de COVID o crees que son igualmente recomendables,
    independientemente de que se presenten o no síntomas?

    Viendo los resultados creo que no es relevante casi que una persona
    sin sintomas se haga una prueba de antigenos.

Un familiar tuyo se ha hecho la misma prueba pero ha dado positivo.

-   ¿Cual es la probabilidad de que tenga COVID dado que ha dado
    positivo? Para calcular esta probabilidad, ¿has tenido que rehacer
    muchos cálculos o te ha valido una sola operación? Comenta el
    porqué.

    Ya conocemos la $P(C | -)$, por tanto podremos calcularlo con 1 sola
    operación:

$$
P(C|+) = 1 - P(C|-) = 1 - \frac{28}{98929} = 0.99972
$$

Como tu familiar no está de acuerdo con el resultado, se hace otra
prueba y da negativo.

-   Actualiza la probabilidad de tener COVID del apartado anterior
    condicionado ahora que en la segunda prueba ha dado negativo.
-   Compara la probabilidad anterior con la probabilidad condicionada
    que obtendrías de tener COVID en caso de que tu familiar se hubiera
    hecho ambos tests a la vez, con idéntico resultado a lo anterior (un
    positivo y un negativo).

$$
P(C|+,-) = \frac{P(-|C,+) \cdot P(C|+)}{P(-|+)} = \frac{P(-|C) \cdot P(C|+)}{P(-|C) \cdot P(C|+) + P(-|C^{c}) \cdot P(C^{c}|+)}
$$

$$
P(C|+,-) = \frac{0.28 \cdot 0.99972}{0.28 \cdot 0.99972 + 0.99 \cdot P(C^{c}|+)}
$$ Por ahora no podemos seguir con el calculo, por tanto calculamos
$P(C^{c}|+)$:

$$
P(C^{c}|+) = \frac{P(+|C^{c}) \cdot P(C^{c})}{P(+|C^{c}) \cdot P(C^{c}) + P(+|C) \cdot P(C)}
$$

$$
P(C^{c}|+) = \frac{0.01 \cdot 0.999}{0.01 \cdot 0.999 + 0.72 \cdot 0.001}
$$

$$
P(C^{c}|+) = 0.9328
$$

Ya podemos seguir con los calculos anteriores:

$$
P(C|+,-) = \frac{0.28 \cdot 0.99972}{0.28 \cdot 0.99972 + 0.99 \cdot P(C^{c}|+)}
$$

$$
P(C|+,-) = \frac{0.28 \cdot 0.99972}{0.28 \cdot 0.99972 + 0.99 \cdot 0.9328}
$$

$$
P(C|+,-) = 0.2326
$$

# PRÁCTICA 2: INFERENCIA Y PREDICIÓN BAYESIANA

### Actividad 1: Estimación de la proporción de lacasitos rojos

Esta es una actividad para realizar en grupos de cuatro o cinco
personas. Vuestro objetivo será hacer inferencia sobre la proporción de
lacasitos que son de color rojo. Para hacerlo se os da un bote de
lacasitos de donde obtendréis vuestros datos

1.  Construye un modelo Bernoulli que pueda describir la situación,
    enumerando: la variable e interés, su distribución de probabilidad
    correspondiente, los datos, el parámetro de interés y los posibles
    valores que puede tomar.

El color de cada lalacasito puede ser rojo o no rojo $=Y$

$$
\pi \rightarrow \text{Proporcion de lacasitos de color rojo}
$$ $$
Y \sim ~ Bernoulli(\pi)
$$

Como hay más de un lacasito, tenemos $n$ núemor de pruebas $$
X \sim Binomial(n,\pi)
$$

2.  Cuenta cuántos lacasitos hay y cuántos de ellos son rojos en el bote
    que se te ha proporcionado. A partir de dichos valores construye la
    función de verosimilitud del modelo. En el bote hay 22 lacasitos con
    4 de ellos rojo ($n = 22$, $X=4$):

Constrimos la funcion de verosimilitud de la Binomial $$
    l(\pi)  \propto \pi^r(1-\pi)^{n-r}
    $$ En donde: $$
    r =  \sum^n_{i=0}X_i 
    $$ $$
    l(\pi)=  \pi^4(1-\pi)^{18}
    $$

3.  Sabiendo que en el paquete vienen lacasitos de 7 colores, propón una
    previa (informativa) conjugada para la proporción de lacasitos rojos
    que asuma que todos los colores tienen la misma probabilidad y con
    una desviación típica de 0.1 unidades.

$E(\pi)= \frac{1}{7}$ $Var(\pi)=0,1^2$

La previa informativa de una Bernoulii o Binomail es una $Beta(a,b)$.

$$
\pi \sim Beta(a,b)
$$

Calculamos $a$ y $b$:

$$ E(\pi)= \frac{a}{a+b}=\frac{1}{7}\rightarrow  7a =a+b$$ $$
6a=b
$$ $$Var(\pi)=\frac{ab}{(a+b)^2(a+b+1)} =0,1^2 \rightarrow$$ $$
\frac{a\cdot 6a}{(a+6a)^2(a+6a+1)}=
$$ $$
\frac{6a^2}{(49a)^2(7a+1)}=
$$

$$
\frac{6}{343a+49}=0,1^2
$$ $$
600 =343a +49 \rightarrow a=1.6064
$$ $$
b=6a=6\cdot 1.6064= 9.6385
$$

$$
\pi \sim Beta(1.6064,9.6385)
$$

4.  Alternativamente, propón una previa no informativa para dicho
    parámetro.

Al pedirnos una previa no informativa, calulamos la previa de Jeffreys
del formulario $$
\pi \sim Beta(\frac{1}{2},\frac{1}{2})
$$

5.  Obtén y representa gráficamente las distribuciones a priori y a
    posteriori de la proporción de lacasitos rojos para ambas previas
    ¿Cuál de ambas distribuciones a posteriori es más apuntada? ¿Por
    qué?

La posteriori la calculamos como:

$$
Beta(r+a, n-r+b)= Beta(5.6064, 26.6385)
$$

Dibujamos las gráficas

```{r}
# Valores de pi
pi_vals <- seq(0, 1, length.out = 1000)

# Parámetros de las distribuciones
# Priori informativa
a1 <- 1.6064
b1 <- 9.6385

# Priori no informativa (Jeffreys)
a2 <- 0.5
b2 <- 0.5

# Posterior informativa
r <- 4
n <- 31
posterior_a1 <- r + a1
posterior_b1 <- n - r + b1

# Posterior no informativa
posterior_a2 <- r + a2
posterior_b2 <- n - r + b2

# Calcular densidades
densities <- data.frame(
  pi = pi_vals,
  Priori_Informativa = dbeta(pi_vals, a1, b1),
  Priori_NoInformativa = dbeta(pi_vals, a2, b2),
  Posterior_Informativa = dbeta(pi_vals, posterior_a1, posterior_b1),
  Posterior_NoInformativa = dbeta(pi_vals, posterior_a2, posterior_b2)
)


densities_long <- densities %>%
  pivot_longer(cols = -pi, names_to = "Distribucion", values_to = "Densidad")

# Graficar
ggplot(densities_long, aes(x = pi, y = Densidad, color = Distribucion)) +
  geom_line(size = 1) +
  labs(title = "Distribuciones a priori y a posteriori de π",
       x = expression(pi), y = "Densidad") +
  scale_color_manual(values = c("blue", "orange", "green", "red"))

```

6.  Utiliza la expresión de la distribución predictiva para un proceso
    Bernoulli que viene en los apuntes de teoría. A partir de ella
    representa la distribución predictiva a posteriori, asumiendo una
    previa no informativa, para el número de lacasitos rojos en una caja
    de 10 unidades ¿Qué probabilidad a posteriori estimas de que la
    nueva caja contenga menos de 2 lacasitos rojos?

Predictiva no inforativa a posteriori $$
x^{*}| x \sim Beta-Bin(m, r+\frac{1}{2},n-r+\frac{1}{2}) 
$$

Siendo que: $m=10$ $a=\frac{7}{2}$ $b=  \frac{29}{2}$

$$
Beta-Bin(10,\frac{7}{2},\frac{29}{2})
$$

Calulamos la probabilidad de X=2:

$P(X=2)$

```{r}
pbbinom(2,10,7/2,29/2)
```

7.  Por último, utiliza ahora los datos de todos los botes de lacasitos
    de todos los compañeros de tu grupo de prácticas. Obtén y representa
    la distribución a posteriori de la proporción de lacasitos rojos,
    utilizando una previa no informativa, junto a la que habías obtenido
    haciendo uso sólo de tus datos.

$$
Beta-Bin(10, 51+\frac{1}{2},348-51+\frac{1}{2})= Beta-Bin(10,51.5,297.5)
$$

```{r}
pbbinom(2,10,51.5,297.5)
```

### Actividad 2: ¿Cuántos hijos/as hasta el primer niño?

Antiguamente las familias estaban muy interesadas en tener descendientes
masculinos. Esto hizo que las familias siguieran teniendo hijos/as hasta
que conseguían al menos un niño. A veces solía tomar tanto tiempo que
pensaban que la probabilidad de tener un niño era menor de 0.5.
Supongamos que se observan el siguiente número de hijos hasta que
conseguir al niño $(3,4,2,3,3,2,1,5,8,2)$ para un conjunto de 10
familias. Basado en estos datos:

1.  Construye un modelo que pueda describir la situación, enumerando: la
    variable de interés, su distribución de probabilidad correspondiente
    (ayuda: ¿distribución geométrica?), los datos, el parámetro de
    interés y los posibles valores que puede tomar

$$
X = \text{Número de hijos hasta primer chico}
$$

$$
X \in [0,\inf +] 
$$

$$
X \sim Geometrica(\pi)
$$

$$
\pi = \text{Probabilidad de que el hijo sea mujer}
$$ 2. Construye la verosimilitud de los datos.

Constrimos la funcion de verosimilitud de la geometrica: $$
l(\pi) \propto(1-\pi)^{\sum x_i -n}\pi^n 
$$ $$
l(\pi) \propto  (1-\pi)^{33-10}\pi^{10}
$$

3.  Propón una previa conjugada informativa que asuma la misma
    probabilidad para ambos sexos y una desviación típica a priori para
    dicho parámetro de 0.1.

La previa conjugada de una $Geométrica$ es una $Beta(a,b)$.

Calculamos $a$ y $b$:

$$ E(\pi)= \frac{a}{a+b}=0.5\rightarrow  a=0.5(a+b)$$ $$
a=b
$$ $$Var(\pi)=\frac{ab}{(a+b)^2(a+b+1)} =0,1^2 \rightarrow$$ $$
\frac{a^2}{(2a)^2(2a+1)}=
$$ $$
\frac{a^2}{4a^2(2a+1)}=
$$

$$
\frac{1}{4(2a+1)}=0,1^2
$$ $$
1=0.04(2a+1) 
$$ $$
a=\frac{1-0.04}{0.08} =12
$$

$$
a=b=12
$$

$$
\pi \sim Beta(12,12)
$$

4.  Obtén la distribución a posteriori del parámetro y representa las
    distribuciones a priori y a posteriori ¿Te parece que la información
    inicial que has utilizado está muy de acuerdo con lo observado en
    los datos de tu población?

La distribución a posteriori de una geométrica sigue la siguiente
formula: $$
 \pi | x \sim Beta(n+a, \sum x_i -n +b) \rightarrow
 $$ $$
  \pi | x \sim Beta(10+12, 33 -10+12) =
 $$ $$
 Beta(22,35)
 $$

```{r}
# Valores de pi
pi_vals <- seq(0, 1, length.out = 1000)

# Parámetros de las distribuciones
# Priori informativa
a <- 12
b <- 12

# Posterior informativa
xi <- c(3,4,2,3,3,2,1,5,8,2)
n <- 10
posterior_a <- n+a
posterior_b <- sum(xi) - n +b

# Calcular densidades
densities <- data.frame(
  pi = pi_vals,
  Priori_Informativa = dbeta(pi_vals, a, b),
  Posterior_Informativa = dbeta(pi_vals, posterior_a, posterior_b)
)


densities_long <- densities %>%
  pivot_longer(cols = -pi, names_to = "Distribucion", values_to = "Densidad")

# Graficar
ggplot(densities_long, aes(x = pi, y = Densidad, color = Distribucion)) +
  geom_line(size = 1) +
  labs(title = "Distribuciones a priori y a posteriori de π",
       x = expression(pi), y = "Densidad") +
  scale_color_manual(values = c("blue", "orange"))

```

5.  Deduce una distribución inicial no informativa para el porcentaje de
    niños sobre el total de hijos/as de las familias. Calcula la
    posterior para dicha previa. Representa y compara la distribución a
    posteriori correspondiente a ambas previas ¿Observas diferencias
    importantes entre ambas distribuciones a posteriori? ¿A qué crees
    que se deben?

Segun el foruario la información previa de Jeffreys de una geométrica
es: $$
\pi \sim Beta(0, \frac{1}{2})
$$ Y la posteriori de no informativa:

$$
\pi | x \sim Beta(n, \sum x_i -n +\frac{1}{2}) \rightarrow
$$

$$
\pi | x \sim Beta(10, 33-10 +\frac{1}{2}) =
$$ $$
Beta(10,23.5)
$$

```{r}
# Valores de pi
pi_vals <- seq(0, 1, length.out = 1000)

# Parámetros de las distribuciones
# Priori informativa
a2 <- 0
b2 <- 1/2

# Posterior informativa
xi <- c(3,4,2,3,3,2,1,5,8,2)

posterior_a2 <- n+a2
posterior_b2 <- sum(xi) - n +b2

# Calcular densidades
densities <- data.frame(
  pi = pi_vals,
  Posterior_Informativa = dbeta(pi_vals, posterior_a, posterior_b),
  Posterior_NoInformativa = dbeta(pi_vals, posterior_a2, posterior_b2)
)

densities_long <- densities %>%
  pivot_longer(cols = -pi, names_to = "Distribucion", values_to = "Densidad")

# Graficar
ggplot(densities_long, aes(x = pi, y = Densidad, color = Distribucion)) +
  geom_line(size = 1) +
  labs(title = "Distribuciones Informativa y No Informativa a posteriori de π",
       x = expression(pi), y = "Densidad") +
  scale_color_manual(values = c("orange", "blue"))
```

Podemos ver como la no informativa refleja mayor incertidumbre sobre la
probabilidad de tener hijos varones. Mientras que en la otra es una
grafica más apuntada, que refleja la simetría en las proporciones de
niños y niñas.

6.  Por último, vamos a comparar los resultados bayesianos que hemos
    obtenido con los que obtendríamos con un procedimiento frecuentista.
    Utilizando la función de verosimilitud que has determinado
    previamente halla el estimador máximo verosímil para la proporción
    de descendientes masculinos. Representa el estimador máximo
    verosimil, como una línea vertical, junto a las distribuciones a
    posteriori del ejercicio anterior ¿Cuál de los dos previas
    utilizadas hasta ahora te parece más oportuna desde un punto de
    vista frecuentista?

Resolevmos la Verosimilitud Primero aplicamos logaritmos a la ecuación

$$
 log (l(\pi)) = 23\cdot log(1-\pi) + 10\cdot log (\pi) 
$$

Ahora tenemos que aplicar la derivada parcial sobre la variable de
interes y igualar a 0.

$$
\frac{\partial log (l(\pi))}{\partial \pi}= \frac{10}{\pi}- \frac{23}{1-\pi} \rightarrow
$$

$$
\frac{10}{\pi}- \frac{23}{1-\pi} = 0
$$ $$
\frac{10}{\pi}= \frac{23}{1-\pi}
$$ $$
10(1-\pi) =23\pi
$$

$$
10=23\pi +10\pi
$$ $$
\hat{\pi}_{EMV} =\frac{10}{33} 
$$

```{r}
emv <- 10/33
ggplot(densities_long, aes(x = pi, y = Densidad, color = Distribucion)) +
  geom_line(size = 1) +
  geom_vline(xintercept = emv, color = "red", linetype = "dashed", size = 1)+
  labs(title = "Comparación de Distribuciones a Posteriori con el EMV  ",
       x = expression(pi), y = "Densidad") +
  scale_color_manual(values = c("orange", "blue"))
```

Desde un punto de vista frecuentista se usaria la posterior no
informativa, dado que esta mas centrada en el $\hat{\pi}_{EMV}$, esto se
da dado que el $\hat{\pi}_{EMV}$ ya que no introduce información
adicional.

# PRÁCTICA 3: INFERENCIA Y PREDICCIÓN BAYESIANA

## Actividad 1

Para cada una de las situaciones que se describen a continuación
construye un modelo probabilístico apropiado, enumerando: la variable de
interés, su distribución de probabilidad correspondiente, los datos, el
parámetro de interés y los valores posibles posibles que puede tomar.

**Escenario 1:** Estimación de la altura media de los alumnos de la ETSE

Se pretende estimar la altura media de los alumnos de la ETSE, con ese
objetivo recogimos la altura de cada uno de los alumnos de un grupo de
prácticas de Modelos Bayesianos. Dichas alturas son: (168, 174, 182,
167, 168, 155, 154, 164, 154, 160, 176, 165, 149, 160, 177, 150, 179,
174). Asumiremos la desviación típica de las alturas de los alumnos de
la ETSE como un valor conocido e igual a 10 unidades.

-   Variable de Interés: $X$ -\> Altura, en cm, de los alumnos de la
    ETSE

-   Distribución de Probabilidad: $X \sim N(\mu, \sigma^2 = 10^2)$

-   Datos: listado comn 18 alturas (168, 174, 182, 167, 168, 155, 154,
    164, 154, 160, 176, 165, 149, 160, 177, 150, 179, 174)

-   Parámetro de Interés: $\mu$ (media de alturas, en cm, de los alumnos
    de la ETSE)

-   Valores posibles que puede tomar: $\mu \in R^+$

**Escenario 2:** Estimación del número medio de palabras en una página
de Game of Thrones

Estamos interesados en estimar el número medio de palabras por página
del libro Game of Thrones. Para ello se toma una muestra aleatoria de 10
páginas del libro donde se observan los siguientes números de palabras
por página: (103, 94, 96, 95, 103, 116, 97, 87, 114, 101, 90, 96, 83,
72).

-   Variable de Interés: $Y$ -\> Número de palabras por página

-   Distribución de Probabilidad: $Y \sim Poisson(\lambda)$

-   Datos: Muestra aleatoria de 14 páginas donde se observan los
    siguientes números de palabras por página (103, 94, 96, 95, 103,
    116, 97, 87, 114, 101, 90, 96, 83, 72).

-   Parámetro de Interés: $\lambda$ (media de palabras por página)

-   Valores posibles que puede tomar: $\lambda \in N^+$

**Escenario 3:** Estimación de la frecuencia de paso de la línea 63 por
el Campus de Burjassot

Queremos estudiar la frecuencia de paso de los autobuses de la línea 63
por el campus de Burjassot. Para ello se recoge el tiempo entre llegadas
de los autobuses a la parada situada frente al campus. Dichos tiempos en
minutos son: (15.7, 16.9, 22.8, 12.1, 36.1, 22.5, 12.9, 14.6, 26.2,
15.6). Asumiremos que los tiempos de llegada son completamente
independientes entre sí, por lo que la distribución de tiempos entre
llegadas se adecúa a una distribución exponencial

-   Variable de Interés: $Z$ -\> Tiempo entre llegadas de los autobuses

-   Distribución de Probabilidad: $Z \sim Exp(\lambda)$

-   Datos: Tiempo entre llegadas de los autobuses a la parada situada
    frente al campus. (15.7, 16.9, 22.8, 12.1, 36.1, 22.5, 12.9, 14.6,
    26.2, 15.6)

-   Parámetro de Interés: $\frac{1}{\lambda}$ (media de tiempo entre
    llegadas de los autobuses)

-   Valores posibles que puede tomar: $[0, +\infty)$

## Actividad 2

Volviendo al escenario 1 de los descritos en la actividad anterior, y
haciendo uso del formulario de estadística bayesiana que tenéis
disponible en el aula virtual resuelve las siguientes cuestiones:

**1.-** Plantea una distribución previa conjugada para la altura media
de los alumnos de la ETSE que asuma que dicha altura está en torno a 170
cm, con una desviación típica de 2 cm, y obtén la distribución a
posteriori correspondiente.

Distribución previa conjugada (del formulario):

$$
\mu \sim N(\nu=170, \tau=2^2)
$$

Distribución a posteriori (del formulario también):

Para ello hará falta calcular w:

$$
w = \frac{ \frac{ \sigma^{2} }{ n } }{ \frac{ \sigma^{2} }{ n } + \tau^2 } = \frac{ \frac{ 10^{2} }{ 18 } }{ \frac{ 10^{2} }{ 18 } + 2^2 } = \frac{25}{43} \simeq 0.58
$$

Una vez calculada w mostramos como queda la distribución a posteriori

$$
\mu | \vec{x} \sim N(w \nu + (1-w) \overline{x}, \ \frac{ \sigma^{2} }{n}(1-w))
$$

$$
\mu | \vec{x} \sim N\left( \frac{25}{43} \cdot 170 + \left(1 - \frac{25}{43} \right) \cdot \frac{496}{3}, \ \frac{ 10^{2} }{18} \cdot \left( 1 - \frac{25}{43}\right) \right)
$$

$$
\mu | \vec{x} \sim N\left( \frac{7226}{43} ,\frac{100}{43}  \right) \simeq N\left( 168.05, \ 2.33 \right)
$$

**2.-** Representa las distribuciones a priori y a posteriori de la
altura media de los alumnos de la ETSE obtenidas en el apartado
anterior.

```{r}
mu.prio <- 170
sd.prio <- 2

mu.post <- 7226/43
sd.post <- sqrt(100/43)

x <- seq(155, 195, length.out = 100) # Valores de x

# Calculamos las dist. a priori y a posteriori
dist.priori <- dnorm(x, mean = mu.prio, sd = sd.prio)  # Densidad normal estándar
dist.posteriori <- dnorm(x, mean = mu.post, sd = sd.post)

plot(x, dist.priori, type = "l", col = "blue", lwd = 2, 
     main = "Densidad de la distribución normal",
     xlab = "x", ylab = "f(x)",
          ylim = c(0, 0.4))
lines(x, dist.posteriori, col = 'green', lwd = 2)

legend("topright", legend = c("Distribución a priori", "Distribución a posteriori"),
       col = c("blue", "green"), lwd = 2)

```

**3.-** Describe la distribución a posteriori:

-   mediante estimaciones puntuales tales como la media a posteriori, la
    moda a posteriori y la mediana a posteriori;

```{r}

# Genero valores de la distribución a posteriori
datos.posteriori <- rnorm(500, mean = mu.post, sd = sd.post)

media <- mean(datos.posteriori)
moda <- mlv(datos.posteriori, method = 'kernel') # 'kernel' porque son datos continuos, sino 'mfv'
mediana <- median(datos.posteriori)

print(paste('La media es: ', media))
print(paste('La moda es: ', moda))
print(paste('La mediana es: ', mediana))

```

-   mediante un intervalo creíble del 95 % para la altura media

```{r}

# Calculamos los cuantiles al 2.5% y 97.5%
q025 <- qnorm(0.025, mean = mu.post, sd = sd.post)
q975 <- qnorm(0.975, mean = mu.post, sd = sd.post)

print(paste('El Intervalo de Credibilidad al 95% es: [', q025, ':', q975 ,']'))
```

**4.-** Contrasta si la estatura media de los alumnos de la ETSE es
inferior a 165 cm, la altura media de los alumnos de la UV. Muestra
ambas probabilidades posteriores utilizadas en el contraste en una
figura.

$H_0: \mu < 165$ $H_a: \mu \geq 165$

```{r}
prob_post <- pnorm(165, mean = mu.post, sd = sd.post)
prob_post
```

$P(\mu < 165 | datos) = 0.0235$

Se rechaza la hipótesis nula

**5.-** Obtén la distribución de la altura de un nuevo alumno cualquiera
de la ETSE, tanto antes como después de haber observado los datos.

Antes de haber observado los datos lo que se debe hacer es comprobar su
distribución predictiva a priori.

La distribución predictiva a priori para una normal de la cual se conoce
su varianza es la siguiente:

$$x^* \sim  N(\nu, \sigma^2 + \tau^2)$$ $$x^* \sim  N(170, 10^2 + 2^2)$$
$$x^* \sim  N(\mu=170, \sigma^2=104)$$

```{r}

mu.pred.prio <- 170
sd.pred.prio <- sqrt(104)

x <- seq(100, 250, length.out = 1000)

dist.pred.priori <- dnorm(x, mean = mu.pred.prio, sd = sd.pred.prio)  

plot(x, dist.pred.priori, type = "l", col = "blue", lwd = 2, 
     main = "Densidad de la distribución predictiva a priori",
     xlab = "x", ylab = "f(x)")

```

Si tenemos en cuenta los datos observados, entonces se utilizará la
distribución predictiva a posteriori.

La distribución predictiva a posteriori para una normal de la cual se
conoce su varianza es la siguiente:

$$x^*| \textbf{x} \sim  N(w \cdot \nu + (1-w) \cdot \bar{x}, \sigma^2 + \frac{\sigma^2}{n} \cdot (1-w)), \space Donde \space w=\frac{\frac{\sigma^2}{n}}{\frac{\sigma^2}{n}+\tau^2} $$

```{r}
datos.alumnos.etse <- c(168, 174, 182, 167, 168, 155, 154, 164, 154, 160, 176, 165, 149, 160, 177, 150, 179, 174)

# Calculamos w, mu.pred.post, sd.pred.post
w <- (10^2/18)/((10^2/18)+2^2)

mu.pred.post <- w*170+(1-w)*mean(datos.alumnos.etse)
sd.pred.post <- sqrt(10^2+(10^2/18)*(1-w))

x <- seq(100, 250, length.out = 1000)

dist.pred.posteriori <- dnorm(x, mean = mu.pred.post, sd = sd.pred.post) 

plot(x, dist.pred.priori, type = "l", col = "blue", lwd = 2, 
     main = "Densidad de la distribución predictiva a priori",
     xlab = "x", ylab = "f(x)",
     ylim = c(0,0.06))
lines(x, dist.pred.posteriori, col = 'green', lwd = 2)

legend("topright", legend = c("Distribución predictiva a priori", "Distribución predictiva a posteriori"),
       col = c("blue", "green"), lwd = 2)

```

**6.-** ¿Cuál es la probabilidad a priori de que la altura de este nuevo
alumno sea superior a 180 cm? ¿Y la a posteriori?

```{r}
# Probabilitat P(mu < 180) per a priori
pred_prob_pri <- 1 - pnorm(180, mean = mu.pred.prio, sd = sd.pred.prio)
pred_prob_pri

# Probabilitat P(mu < 180) per a posteriori
pred_prob_post <- 1 - pnorm(180, mean = mu.pred.post, sd = sd.pred.post)
pred_prob_post
```

Se aceptan las hipótesis nulas

## Actividad 3

Volviendo al escenario 3 de los descritos en la actividad anterior, y
haciendo uso del formulario de estadística bayesiana que tenéis
disponible en el aula virtual resuelve las siguientes cuestiones:

```{r}
datos.iniciales <- c(15.7, 16.9, 22.8, 12.1, 36.1, 22.5, 12.9, 14.6, 26.2, 15.6)
n <- length(datos.iniciales)
n
```

**1.-** La EMT informa que la frecuencia de paso de los autobuses es de
15 minutos, por tanto debería llegar 1/15 autobuses por minuto. Plantea
una distribución previa conjugada para el parámetro de la distribución
exponencial (número de llegadas a la parada por minuto) acorde a esta
información y con desviación típica de 0.05 unidades.

Vamos a obtener los valores de a y b de la distribución a priori
conjugada:

Tenemos que $\frac{a}{b} = \frac{1}{15}$, por tanto, $a = \frac{b}{15}$

Por otro lado, tenemos que $\frac{a}{b^2}=0.05^2$ de donde obtenemos que
$a = 0.05^2 \cdot b^2$

Con esto podemos obtener los valores de $a$ y $b$ que son los
siguientes: $a = \frac{16}{9}$ y $b=\frac{80}{3}$

Y por tanto, podemos definir la distribución a priori conjugada de
$\frac{1}{\lambda}$

$$
\frac{1}{\lambda} \sim Gamma(a, b) = Gamma(\frac{16}{9}, \frac{80}{3})
$$

```{r}
a.priori <- 16/9
b.priori <- 80/3

x <- seq(0, 1, length.out = 1000)
dist.priori <- dgamma(x, shape = a.priori, rate = b.priori)
plot(x, dist.priori, type = "l", col = "blue", lwd = 2, 
     main = "Densidad de la Gamma a priori",
     xlab = "x", ylab = "f(x)")
```

**2.-** Calcula la distribución a posteriori correspondiente a esta
prior y resume dicha distribución mediante su media, moda y mediana a
posteriori, así como un intervalo de credibilidad a posteriori del 95 %.
Representa toda la información que has calculado.

$$
\frac{1}{\lambda} | x \sim Gamma\left(n+a, \ \sum_{i=1}^{n}{x_{i}}+b \right)
$$

$$
\frac{1}{\lambda} | x \sim Gamma\left( 10 + \frac{16}{9}, \ 15.7 + 16.9 + \cdots + 26.2 + 15.6 + \frac{80}{3} \right)
$$

```{r}
a.posteriori <- n+a.priori
b.posteriori <- sum(datos.iniciales)+b.priori

x <- seq(0, 1, length.out = 1000)
dist.posteriori <- dgamma(x, shape = a.posteriori, rate = b.posteriori)
plot(x, dist.priori, type = "l", col = "blue", lwd = 2, 
     main = "Densidad de la Gamma a posteriori",
     xlab = "x", ylab = "f(x)",
     ylim=c(0,30))
lines(x, dist.posteriori, col = 'green', lwd = 2)

legend("topright", legend = c("Distribución predictiva a priori", "Distribución predictiva a posteriori"),
       col = c("blue", "green"), lwd = 2)
```

Calculo de:

-   Media de la gamma

```{r}
a.posteriori / b.posteriori
```

-   Moda de una gamma

```{r}
(a.posteriori - 1)/b.posteriori
```

-   Mediana de una gamma

```{r}
mediana <- qgamma(0.5, shape = a.posteriori, rate = b.posteriori)
mediana
```

-   Intervalo de credibilidad al 95%

**3.-** Según comentábamos, la EMT anuncia una tasa de llegada de 1/15
autobuses por minuto para el tramo horario en el que se han tomado las
mediciones. Contrasta la hipótesis de que la tasa real de llegadas es
menor que lo anunciado por la EMT.

$$
H_{0}: \lambda < 1/15 \\
H_{A}: \lambda \geq 1/15
$$

```{r}
pgamma(1/15, shape = a.posteriori, rate = b.posteriori)
```

No hay evidencia suficiente para rechazar la hipótesis nula $H_{0}$ pero
parece bastante probable que sea $> \frac{1}{15}$

# PRÁCTICA 4: INFERENCIA BASADA EN SIMULACIÓN EN MODELOS MÁS COMPLEJOS

## Actividad 1: Inferencia haciendo uso de simulación en una población Normal con media y varianza desconocidas

Se pretende estimar la altura media de los alumnos de la ETSE. Con ese
objetivo se recoge la altura de cada uno de los alumnos de un grupo de
prácticas de Modelos Bayesianos. Dichas alturas son: (168, 174, 182,
167, 168, 155, 154, 164, 154, 160, 176, 165, 149, 160, 177, 150, 179,
174). A diferencia de la práctica anterior supondremos que la desviación
típica de las alturas de los alumnos de la ETSE es desconocida, ya que
parece un supuesto bastante más realista que el que asumíamos allí.

```{r}
datos <-  c(168, 174, 182, 167, 168, 155, 154, 164, 154, 160, 176, 165, 149, 160, 177, 150, 179, 174)
```

**1.** Precisa los parámetros del modelo estadístico necesario para
estudiar el problema propuesto. Plantea una previa no informativa para
dichos parámetros y deduce la distribución a posteriori analítica
correspondiente. ¿Dispones/conoces de herramientas en $R$ para
representar/reproducir dicha distribución, calcular sus cuantiles o
simular valores de ella?

Utilizando el formulario plantearemos la siguiente previa no
informativa:

$$
p(\mu, \sigma^{2}) \propto (\sigma^{2})^{-1}
$$

Además, la distribución a posteriori conjunta quedará de la siguiente
forma:

$$
p( \mu, \sigma^{2} | \textbf{x} ) =
\sigma^{-n-2} e^{- \frac{1}{2 \sigma^{2}} [(n-1)s^{2}+n(\bar{x}-\mu)^{2}]}
$$

No se dispone de muchos métodos con R para poder representar/reproducir
la distribución o hacer otros cálculos varios ya que por un lado no
poseemos las constante de integración necesarias para poder integrar y
por otro lado las distribuciones obtenidas no se parecen a otras
distribuciones de las conocidas.

Uno de los principales problemas que se plantea en estudios de
inferencia bayesiana con varios parámetros es que la distribución a
posteriori correspondiente es multivariante y que difícilmente será una
distribución multivariante conocida. En consecuencia, resulta difícil
trabajar con dichas distribuciones, resumirlas, hacer
cálculos/contrastes de manera analítica (mediante desarrollos
matemáticos),... Vamos a ver cómo la simulación de muestras aleatorias
de dichas distribuciones resulta un recurso utilísimo en este contexto.

En nuestro caso concreto, dado que $P(\mu, \sigma^{2} | \textbf{x})$
sigue una distribución no estándar, nos vamos a conformar con obtener
una “simple” muestra aleatoria de valores de
$\mu, \sigma^{2} | \textbf{x}$. Como el muestrear de ambos valores
conjuntamente puede ser complicado, nos planteamos simular una muestra
$\sigma_{1},..., \sigma_{n}$ de $\sigma^{2} | \textbf{x}$ y una vez
obtenida esta muestra simularemos otra ${\mu_{1},..., \mu_{n}}$ de
$\mu | \sigma^{2}, \textbf{x}$ ya que en el formulario de estadística
bayesiana de la asignatura se nos dan ambas distribuciones y son
relativamente manejables. La unión de ambas muestras
{$(\sigma_{1}, \mu_{1}),...,(\sigma_{n}, \mu_{n})$} $=$
{$(\sigma, \mu)_{1},...,(\sigma, \mu)_{n}$} supone una muestra de la
distribución conjunta de $(\mu, \sigma^{2}) | \textbf{x}$. Veamos cómo
se aplica todo esto en la práctica.

**2.** Según se refleja en el formulario,
$\sigma^{2} | \textbf{x} \sim inv-\chi^{2} (n-1, s^{2})$ sigue una
distribución chi-cuadrado invertida con $n - 1$ grados de libertad y con
parámetro de escala $s^{2}$. Utiliza la librería `LaplacesDemon`
(funciones `dinvchisq`, `rinvchisq`) para visualizar la distribución a
posteriori $\sigma^{2} | \textbf{x}$ que corresponde a nuestro estudio.
Obtén una muestra de 10,000 valores aleatorios de dicha distribución y
representa su histograma con la función de densidad correspondiente
superpuesta.

```{r}
n <- length(datos)

nu <- n-1
tau <- (1/(n-1))*sum((datos-mean(datos))^2)

set.seed(1)
datos.rinvchisq <- rinvchisq(10000, df = nu, scale = tau)
hist(datos.rinvchisq, 
     probability = TRUE, 
     breaks = 100, 
     col = "lightblue")
curve(dinvchisq(x, nu, tau), 
      from = 0.001, 
      to = max(datos.rinvchisq), 
      col = "darkblue", 
      lwd = 2, 
      add = TRUE)
```

**3.** El paquete `LaplacesDemon` no contiene ninguna función
`qinvchisq` que nos pudiera ser de utilidad para obtener los cuantiles
de $\sigma^{2} | \textbf{x}$, y de ahí calcular, por ejemplo, su mediana
o intervalos de credibilidad a posteriori al $95\%$. Sin embargo, la
muestra aleatoria que has obtenido en el apartado anterior nos puede
valer para aproximar dichos valores. ¿De qué forma? Obtén la mediana e
intervalo de credibilidad al $95\%$ de $\sigma^{2} | \textbf{x}$.

```{r}
# Cálculo de la mediana
mediana <- median(datos.rinvchisq)

# Cálculo del intervalo de confianza
q025 <- quantile(datos.rinvchisq, probs = 0.025)
q975 <- quantile(datos.rinvchisq, probs = 0.975)

print(paste0('Mediana: ', mediana))
print(paste0('Intervalo de credibilidad al 95%: [', q025, ':', q975, ']'))
```

El formulario de la asignatura nos dice que
$\mu | \sigma^{2}, \textbf{x} \sim N(\bar{x}, \frac{\sigma^{2}}{n})$, es
decir, dado cualquier valor de $\sigma^{2}$ conoceríamos la distribución
a posteriori de $\mu$ correspondiente. El problema es que no conocemos
un valor concreto de $\sigma^{2}$ sino su distribución. Sin embargo,
conocemos un montón de valores $\sigma_{1}^{2},...,\sigma_{10000}^{2}$
que hemos generado en la muestra aleatoria del ejercicio anterior y a
partir de cada uno de estos valores podríamos generar un valor simulado
de dicha distribución normal, en concreto,
$\mu_{i} \sim N\left(\bar{x}, \frac{\sigma_{i}^{2}}{n}\right)$,
consiguiendo así una muestra $\mu_{1},...,\mu_{10000}$. Este método de
simulación se conoce como *simulación por composición* y como resultado
obtendremos una muestra aleatoria de $\mu | \sigma^{2}, \textbf{x}$.
Además, tal y como hemos comentado, cada uno de los pares de valores
{$\left(\mu_{i}, \sigma_{i}^{2}\right), \space i=1,...$} generados
siguen la distribución multivariante
$\left(\mu, \sigma^{2}\right) | \textbf{x}$ que nos resulta tan difícil
de manejar matemáticamente.

**4.** Empleando simulación por composición, obtén una muestra de la
distribución a posteriori conjunta
$\left( \mu, \sigma^{2} \right) | \textbf{x}$. Estima la función de
densidad bivariante correspondiente mediante la función `MASS::kde2d`
(`kde2d` estima la función de densidad sobre un grid de valores para
$\mu$ y $\sigma^{2}$ y representa dicha estimación con la función
`image`

```{r}
n <- length(datos)
mu <- mean(datos)
sigma2 <- datos.rinvchisq/n
sigma <- sqrt(sigma2)

datos.mu <- rnorm(10000, mean = mu, sd = sigma)
hist(datos.mu, 
     probability = TRUE, 
     breaks = 30, 
     col = "lightblue")
```

Ahora teniendo valores para $\sigma^{2}$ y $\mu$ sacaremos los
siguientes valores:
{$\left(\mu_{i}, \sigma_{i}^{2}\right), \space i=1,...$}.

Por tanto, con estos datos podemos definir la distribución a posteriori
conjunta $\left( \mu, \sigma^{2} \right) | \textbf{x}$

```{r}
# Estimación de densidad conjunta
kde <- kde2d(datos.mu, datos.rinvchisq, n=100)

# Mostramos graficamente el análisis de la densidad
image(kde, col = terrain.colors(100), 
      xlab = expression(mu), ylab = expression(sigma^2), 
      main = "Densidad conjunta posterior de (mu, sigma^2)")
contour(kde, add = TRUE)

```

**5.** El procedimiento anterior, si ignoramos la muestra generada para
$\sigma^{2}$, genera implícitamente una muestra de valores para $\mu$.
Dicha muestra de valores es a su vez una muestra de la distribución
marginal a posteriori $\mu | \textbf{x}$. En el formulario de la
asignatura se nos informa que
$P(\mu |\textbf{x}) \sim t_{n-1} \left( \bar{x}, \frac{s^{2}}{n} \right)$,
comprueba que la muestra que has generado corresponde a dicha
distribución haciendo un histograma de la muestra de $\mu$ que has
generado ya y superponiendo la función de densidad correspondiente que
aparece en el formulario (utiliza la función `dt.scaled` de la librería
`metRology` ya que `dt` no permite incluir el parámetro de escala
$\frac{s^{2}}{n}$.

```{r}
n <- length(datos)

media <- mean(datos)
escala <- ((1/(n-1))*sum((datos-mean(datos))^2))/n
escala_param <- sqrt(escala)

hist(datos.mu, 
     probability = TRUE, 
     breaks = 50, 
     col = "lightblue")
curve(dt.scaled(x, mean=media, sd=escala_param, df=n-1),
      col = "darkblue", lwd = 2, add = TRUE)
```

Una de las grandes ventajas de la inferencia basada en simulación es que
si $x_{1},...,x_{n}$ es una muestra de la variable aleatoria $X$
entonces $f(x_{1}),...,f(x_{n})$ será, de la misma forma, una muestra de
la variable aleatoria $f(X)$. Así, podremos utilizar esta segunda
muestra para hacer inferencia sobre $f(X)$ (sin desarrollos matemáticos
de por medio) de la misma manera que utilizábamos la primera para hacer
inferencia sobre $X$. De manera similar, si
$(x_{1}, y_{1}),...,(x_{n}, y_{n})$ fuera una muestra del vector de
variables $(X, Y)$ entonces $g(x_{1}, y_{1}),..., g(x_{n}, y_{n})$ sería
una muestra de aleatoria de la variable $g(X,Y)$

**6.** A partir de las muestras de variables de que dispones estima, y
representa, la distribución a posteriori de la desviación típica
$\sigma$ de las alturas de los alumnos de la ETSE. Representa la
estimación de la función de densidad obtenida haciendo uso de la función
`density`.

Si la muestra que tengo se refiere a $\sigma^{2}$ entonces primeramente
transformo las variables a desviaciones estandard $\sigma$.

```{r}
datos.sd <- sqrt(datos.rinvchisq)
density_sigma <- density(datos.sd)
plot(density_sigma, main="Distribución posterior de sigma", xlab="Desviación estándar (sigma)")

```

**7.** A partir de las muestras de las variables de que dispones estima
la media a posteriori y da un intervalo de credibilidad (a posteriori)
al $95\%$ del coeficiente de variación ($\frac{\sigma}{\mu}$) de las
alturas de los alumnos de la ETSE.

A continuación, sacamos la media a posteriori para $\mu$ y $\sigma^{2}$:

-   Para $\mu$:

```{r}
media.mu <- mean(datos.mu)
media.mu
```

-   Para $\sigma^2$:

```{r}
media.sigma2 <- mean(datos.rinvchisq)
media.sigma2
```

Ahora se creará el Intervalo de Credibilidad al $95\%$ de
$\frac{\sigma}{\mu}$:

```{r}
coef.variacion <- datos.sd/datos.mu

# Cálculo del intervalo de confianza
q025 <- quantile(coef.variacion, probs = 0.025)
q975 <- quantile(coef.variacion, probs = 0.975)
print(paste0('Intervalo de credibilidad del coeficiente de variación al 95%: [', q025, ':', q975, ']'))

```

**8.** Por último, querríamos valorar de nuevo la hipótesis
$H_{0}: \mu < 165$, pero sin asumir conocida la varianza de las alturas
de los alumnos de la ETSE. Calcula, basado en tu muestra, la
probabilidad a posteriori de esta hipótesis y valora si es más probable
ella o su contraria $H_{1}: \mu \ge 165$.

Como no asumimos conocida la varianza de las alturas utilizaremos la
siguiente distribución de la media del formulario:
$P(\mu |\textbf{x}) \sim t_{n-1} \left( \bar{x}, \frac{s^{2}}{n} \right)$

```{r}
n <- length(datos)

media <- mean(datos)
escala <- ((1/(n-1))*sum((datos-mean(datos))^2))/n
escala_param <- sqrt(escala)

pt.scaled(q = 165, mean=media, sd=escala_param, df=n-1)
```

En este caso no podemos rechazar la $H_0$, ni aceptar $H_{1}$, ya que
$H_1$ es más probable, pero tampoco por mucho.

# PRÁCTICA 5: SIMULACIÓN MCMC CON JAGS

### Actividad 1: Regresión logística con JAGS

En $1986$ tuvo lugar uno de los más trágicos accidentes de la era
espacial al explotar nada más despegar el transbordador espacial
Challenger. Por lo que se pudo analizar después, el accidente se podría
haber evitado si se hubiera conocido la alta probabilidad de fallo de
unas piezas clave que controlaban la presión cuando bajaba la
temperatura. Los siguientes datos muestran las temperaturas (en grados
Farenheit) que había en las $23$ ocasiones previas que había realizado
un lanzamiento y para cada una de ellas se presenta también el número de
juntas tóricas rotas (de $6$). Las juntas tóricas eran algo importante
para regular la presión en el momento del lanzamiento.

|                                |     |     |     |     |     |     |     |     |     |     |     |     |
|------|------|------|------|------|------|------|------|------|------|------|------|------|
| Temperatura                    | 66  | 70  | 69  | 68  | 67  | 72  | 73  | 70  | 57  | 63  | 70  | 78  |
| Número de juntas tóricas rotas | 0   | 1   | 0   | 0   | 0   | 0   | 0   | 0   | 1   | 1   | 1   | 0   |

|                                |     |     |     |     |     |     |     |     |     |     |     |
|------|------|------|------|------|------|------|------|------|------|------|------|
| Temperatura                    | 67  | 53  | 67  | 75  | 70  | 81  | 76  | 79  | 75  | 76  | 58  |
| Número de juntas tóricas rotas | 0   | 2   | 0   | 0   | 0   | 0   | 0   | 0   | 2   | 0   | 1   |

Tu objetivo será analizar este conjunto de datos utilizando **JAGS**
para simular de la muestra a posteriori con MCMC.

1.  Describe en detalle el modelo que te permite explicar el número de
    juntas tóricas rotas a través de la probabilidad de fallo en función
    de la temperatura. A la hora de asignar distribución inicial a los
    parámetros del modelo piensa que **JAGS**, la herramienta de
    simulación que vamos a utilizar, no permite el uso de distribuciones
    impropias ¿Qué propuesta de distribución inicial te parece adecuada
    para estos parámetros y válida en **JAGS**?

    Variable de respuesta: Número de juntas tóricas rotas

    Variable explicativa: Temperatura

    Como son conteos de juntas tóricas rotas sabemos que la variable de
    respuesta seguirá una distribución de Poisson y por tanto la
    regresión a aplicar será la de Poisson.

2.  Utiliza **JAGS** para hacer inferencia sobre el modelo de regresión
    logística que acabas de describir.

    El modelo descrito anteriormente podría adaptarse a lo siguiente:

```{r}
cat(
"model {
  
  # Definimos la verosimilitud
  for (i in 1:length(JUNTAS_ROTAS)) {
    JUNTAS_ROTAS[i] ~ dpois(lambda[i])
    log(lambda[i]) <- beta0 + beta1 * TEMPERATURAS[i]
  }
  
  # A priori
  beta0 ~ dnorm(0, 0.001)
  beta1 ~ dnorm(0, 0.001)
  
}", file="modelos_jags/poissonReg.jags")
```

Con el modelo ya definido, definimos los argumentos que nos valdrán para
ejecutarlo:

```{r}
datos <- list(JUNTAS_ROTAS = c(0,1,0,0,0,0,0,0,1,1,1,0,0,2,0,0,0,0,0,0,2,0,1),
              TEMPERATURAS = c(66,70,69,68,67,72,73,70,57,63,70,78,67,53,67,75,70,81,76,79,75,76,58))

iniciales <- function(){list(beta0=rnorm(1), beta1=rnorm(1))}

parametros <- c('beta0', 'beta1')
```

Una vez disponemos de los argumentos llamamos a JAGS para llevar a cabo
la simulación:

```{r}
set.seed(1)

resul.pois <- jagsUI::jags(data = datos, inits=iniciales, parameters.to.save=parametros,
                           model.file = 'modelos_jags/poissonReg.jags', 
                           n.chains=5, n.iter=10000, n.burnin=1000, n.thin=15)

resul.pois
```

3.  Valora la convergencia de la simulación utilizando la función
    `traceplot`.

```{r}
traceplot(resul.pois)
```

Tal y como anticipan los valores de rhat y n.eff la convergencia parece
buena.

4.  Una vez simuladas las muestras de la distribución a posteriori de
    ambos parámetros podemos utilizarlas para hacer inferencia.
    Representa la estimación de la función de densidad de ambos
    parámetros del modelo y resume de la manera que te parezca
    conveniente su distribución a posteriori. Valora nuevamente si la
    pendiente $\beta_{1}$ es mayor o menor que $0$ y qué implicación
    tiene este resultado.

```{r}
plot(resul.pois)
```

5.  **JAGS** también puede ser utilizado para simular de distribuciones
    predictivas. Por ejemplo, en el mismo modelo que has corrido
    previamente, podrías añadir un par de líneas, una con la expresión
    que calcula el valor de la probabilidad (o simplemente su logit)
    para el valor que quieras predecir, y otra en la que generas el
    valor que quieres predecir a partir de la probabilidad anterior.
    Estima, utilizando **JAGS**, la distribución predictiva a posteriori
    del número de juntas tóricas rotas a $28$ grados Fahrenheit ¿Qué
    numero medio de juntas rotas esperarías encontrar en un cohete
    lanzado a esa temperatura?

    Modificamos el codigo anterior para poder contestar a las nuevas
    preguntas.

```{r}
cat(
"model{
  # Definimos la verosimilitud
  for (i in 1:length(JUNTAS_ROTAS)) {
    JUNTAS_ROTAS[i] ~ dpois(lambda[i])
    log(lambda[i]) <- beta0 + beta1 * TEMPERATURAS[i]
  }
    
  # a priori
  beta0 ~dnorm(0,0.0001)
  beta1 ~dnorm(0,0.0001)
  
  #P roturas para 28 Fº
  logit(pinueva)<-beta0+beta1*28
  predictiva~dbin(pinueva,6)
  
}", file="modelos_jags/poissonReg2.jags")
```

Redifinimos los parametros:

```{r}
parametros <- c("beta0", "beta1", "predictiva", "pinueva")
```

Llamamos a JAGS para llevar a cabo la simulación:

```{r}
set.seed(1)

resul.pois2 <- jagsUI::jags(data = datos, inits = iniciales, 
                           parameters.to.save = parametros,
                           model.file = 'modelos_jags/poissonReg2.jags', 
                           n.chains=5, n.iter=10000, n.burnin=1000, n.thin=15)

resul.pois2
```

### Actividad 2: Modelización de conteos haciendo uso de JAGS

El archivo `mining.Rdata` contiene el número anual de accidentes
observados (vector `Count`) en minas de carbón de el Reino Unido durante
el periodo $1851$-$1962$. Adicionalmente, el vector `Year`, contiene el
año correspondiente a cada obseración del periodo de estudio. Esta
última variable ha sido centrada (con valores
$-55.5, -54.5, \dots , 55.5$) para evitar problemas de colinealidad con
el intercept. El objetivo de esta tarea es estudiar la evolución del
número de accidentes anuales como función del año del periodo de
estudio, obviando la estructura de dependencia temporal que pudiera
mostrar dicha serie.

1.  Describe en detalle un modelo que te permita explicar el número de
    accidentes anuales en minas británicas en función del año del
    periodo de estudio. Ten en cuenta nuevamente la limitación de
    **JAGS** en cuanto al uso de distribuciones impropias.

    Variable de respuesta: Número de accidentes en las minas

    Variable explicativa: Año en el que se produjeron

    Como son conteos de accidentes sabemos que la variable de respuesta
    seguirá una distribución de Poisson y por tanto la regresión a
    aplicar será la de Poisson.

2.  Utiliza **JAGS** para hacer inferencia sobre el modelo de regresión
    que acabas de plantear.

```{r}
cat(
  "model{
    #Verosimilitud
    for (i in 1:length(Count)){
      Count[i] ~ dpois(lambda[i])
      log(lambda[i]) <- beta0 + beta1*Year[i]       
    }
    
    # a priori
    beta0 ~dnorm(0,0.0001)
    beta1 ~dnorm(0,0.0001)
  
  }", file = "modelos_jags/accidentes.jags")
```

```         
Con el modelo ya definido, definimos los argumentos que nos valdrán para ejecutarl:
```

```{r}
Year <- c(1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859,
          1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868,
          1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877,
          1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886,
          1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 
          1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 
          1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913,
          1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922,
          1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931,
          1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 
          1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 
          1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 
          1959, 1960, 1961, 1962)
# Modificamos la fecha para que podamos trabajar megor con el modelo, teniendo la media cntrada en 0
media_anyo <- mean(Year)

Year <- Year - media_anyo

Count <- c(4, 5, 4, 1, 0, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6, 3, 3, 5, 4, 5, 3, 1, 
           4, 4, 1, 5, 5, 3, 4, 2, 5, 2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 1, 1, 3, 
           0, 0, 1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0, 
           0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2, 3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 2, 
           0, 0, 0, 1, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1)

datos <- list(Year = Year,
              Count = Count)
  
iniciales <- function(){list(beta0 = rnorm(1), beta1 = rnorm(1))}

parametros <- c("beta0", "beta1")
```

```         
Una vez disponemos de los argumentos llamamos a JAGS para llevar a cabo la simulación:
```

```{r}
set.seed(1)

resul.pois3 <- jagsUI::jags(data=datos, inits= iniciales, parameters = parametros,
                          model.file = "modelos_jags/accidentes.jags", n.chains = 3, 
                          n.iter=10000, n.burnin = 1000, n.thin=15)

resul.pois3 
```

3.  Valora la convergencia de la simulación utilizando la función
    `traceplot`.

```{r}
traceplot(resul.pois3)
```

4.  Interpreta los resultados obtenidos, fundamentalmente en relación al
    efecto del tiempo sobre el número de accidentes ¿De qué forma te
    parece que influyen los años sobre el número de accidentes? ¿Es
    dicha relación significativa? Da (e interpreta) un intervalo de
    credibilidad al $95\%$ para el parámetro que controla dicha
    relación.

    Primero calculamos el intervalo de credibilidad al $95\%$

    ```{r}
    summary(resul.pois3)
    ```

    El intervalo de credibilidad al 95% de $\beta_1$ es $[-0.02354788,
    -0.01394777]$ lo que significa que no incluye el valor 0. Por lo
    tanto, la relación entre los años y el número de accidentes es
    estadísticamente significativa. Como $\beta_1 < 0$ esto significa
    que conforme aumentan los años se espera que el nuemro de accidentes
    baje.

5.  Genera una muestra de la distribución predictiva del número de
    accidentes predichos al año siguiente de concluir el estudio ¿Que
    probabilidad encuentras de que no haya ningún accidente ese año? ¿y
    $2$ o más?

    El modelo predictivo seria el siguiente:

$$
\lambda\_{k+1}=e^{\beta\_0 + \beta*1 Year*{k+1}}
$$
$$
Prediccio ~ Po(\lambda\_{k+1})
$$

```{r}
nuevo_anyo <- 1963 - media_anyo #al anño que queremos calcular le restamos la media para adecuar los datos conforme se ha entrenado al modelo

beta0 <- 0.355
  
beta1 <- -0.019
  
lambda_predict <- exp(beta0 + beta1*nuevo_anyo)
  
  
numero_accidentes <- rpois(1, lambda = lambda_predict)
numero_accidentes

```

Calculamos la probabilidad de que no haya accidentes:

$P(Count = 0)$

```{r}
dpois(0,lambda = lambda_predict)
```

Calculamos la probabilidad de que haya mas de 2 accidentes:

$P(Count\ge 2) = 1- P(Count = 0)+ P(Count = 1)$

```{r}
1 - dpois(0,lambda = lambda_predict) + dpois(1,lambda = lambda_predict)
```

# PRÁCTICA 6: MODELIZACIÓN BAYESIANA AVANZADA

## Actividad 1: Diferencias entre operarios

A la hora de validar el funcionamiento de una máquina muchas veces se
plantea si se producen diferencias según el operario que está a su
cargo. El banco de datos `pulp` de la librería `faraway` estudia este
efecto, concretamente, contiene información sobre el brillo del papel
producido por una máquina en función del operario que la ha manejado.

Plantea un modelo lineal para la variable respuesta brillo del papel, en
el que el operario sea modelizado con un efecto aleatorio para valorar
la variabilidad atribuible a este factor. Utiliza *JAGS* para llevar a
cabo la inferencia sobre el modelo propuesto. Utiliza los estadísticos
proporcionados por *JAGS* para valorar la convergencia de la simulación
¿Encuentras que la principal fuente de variabilidad en el brillo de los
papeles es atribuible a cada papel en concreto o al operario que
manejaba la máquina?

```{r}
data <- pulp
data

brillo <- pulp$bright
operario <- as.numeric(factor(pulp$operator))
```

```{r}
cat(
'model{
  # Definimos la verosimilutud
  for (i in 1:length(DATOS_BRILLO)) {
    DATOS_BRILLO[i] ~ dnorm(mu[i], tau)
    mu[i] <- beta0 + beta1[OPERARIO[i]]
  }
  
  # A priori
  tau <- sigma^(-2)
  sigma ~ dunif(0, 100)
  
  beta0 ~ dnorm(0, 0.001)
  for (j in 1:4) {
    beta1[j] ~ dnorm(0, tauOp)
  }
  tauOp <- sigmaOp^(-2)
  sigmaOp ~ dunif(0, 100)

}'
, file = './modelos_jags/modelo1')
```

```{r}
datos <- list(DATOS_BRILLO = brillo, OPERARIO = operario)

iniciales <- function() {list(beta0 = rnorm(1), beta1 = rnorm(4), # Generamos 4 valores, 1 por operario
                              sigma = runif(1, 0, 100), sigmaOp = runif(1, 0, 100))}

parametros <- c('beta0', 'beta1', 'sigma', 'sigmaOp')

resul.brillo <- jagsUI::jags(data = datos, inits = iniciales, parameters.to.save = parametros,
                             model.file = './modelos_jags/modelo1', 
                             n.iter = 5000, n.burnin = 1000, n.chains = 3, n.thin = 12)
resul.brillo
```

## Actividad 2: Más sobre fallos en maquinas

Los siguientes datos corresponden al número de fallos de distintas
bombas hidráulicas junto con el tiempo de funcionamiento de cada una de
ellas (en miles de horas):

```{r}
fallos <- c(5, 1, 5, 14, 3, 19, 1, 1, 4, 22)
tiempo <- c(94.5, 15.7, 62.9, 126, 5.24, 31.4, 1.05, 1.05, 2.1, 10.5)
```

Nuestro objetivo será modelizar el número de fallos ocurridos por cada
1000 horas de uso, pero cuidado, no tiene sentido modelizar dicho número
directamente ya que si una máquina ha funcionado más tiempo debería
tener más fallos ¿no? Así pues, modelizaremos el número de fallos
asumiendo que su valor esperado es proporcional al tiempo de
funcionamiento de la máquina. Estos pasos te ayudarán en el proceso:

1.  Formula un modelo que estudie el número de fallos de las bombas en
    función de su tiempo de uso, por cada 1000 horas. Utiliza JAGS para
    hacer inferencia y los estadísticos proporcionados para valorar la
    convergencia

```{r}
cat(
'model{
  # Definimos la verosimilutud
  for (i in 1:length(DATOS_FALLOS)) {
    DATOS_FALLOS[i] ~ dpois(lambda*TIEMPO[i])
  }
  
  # A priori
  lambda ~ dunif(0, 1000)
  #lambda ~ dgamma(0.1, 0.1)
}'
, file = './modelos_jags/modelo2')
```

```{r}
datos <- list(DATOS_FALLOS = fallos, TIEMPO = tiempo)

iniciales <- function() {list(lambda = rgamma(1,0.1,0.1))}

parametros <- c('lambda')

resul.fallos1 <- jagsUI::jags(data = datos, inits = iniciales, parameters.to.save = parametros,
                             model.file = './modelos_jags/modelo2', 
                             n.iter = 5000, n.burnin = 1000, n.chains = 3, n.thin = 12)
resul.fallos1
```

*Dado que no tenemos información inicial, utiliza para* $\lambda$ la
previa de Jeffreys del parámetro de la distribución de Poisson

2.  Una vez ajustado el modelo anterior nos planteamos que la tasa de
    fallos, por 1000 horas de uso, podría variar de máquina a máquina.
    En realidad se dispone de más máquinas, aunque solo conocemos datos
    de éstas (siendo nuestro interés el cuantificar la variabilidad
    entre máquinas). Modeliza esta nueva situación con un modelo
    jerárquico (bayesiano) haciendo uso de JAGS, y sus estadísticos para
    valorar la convergencia de la simulación ¿Qué modelo de los que has
    ajustado te parece más oportuno en base al ajuste obtenido?
    ¿Encuentras diferencias entre máquinas según los intervalos de
    credibilidad de cada una de las máquinas que has estudiado?

```{r}
cat(
'model{
  # Definimos la verosimilutud
  for (i in 1:length(DATOS_FALLOS)) {
    DATOS_FALLOS[i] ~ dpois(lambda[i]*TIEMPO[i])
  }
  
  # A priori
  for (i in 1:10) {
    lambda[i] ~ dgamma(alpha, beta)
  }
  
  alpha ~ dexp(0.01)
  beta ~ dexp(0.01)
}'
, file = './modelos_jags/modelo3')
```

```{r}
datos <- list(DATOS_FALLOS = fallos, TIEMPO = tiempo)

iniciales <- function() {list(lambda = rgamma(10,0.1,0.1), alpha=rexp(1, 0.01), beta=rexp(1, 0.01))}

parametros <- c('lambda', 'alpha', 'beta')

resul.fallos1 <- jagsUI::jags(data = datos, inits = iniciales, parameters.to.save = parametros,
                             model.file = './modelos_jags/modelo3', 
                             n.iter = 5000, n.burnin = 1000, n.chains = 3, n.thin = 12)
resul.fallos1
```
